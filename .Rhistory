source("H:/My Drive/Work/QYF/Projects/FNB Fraud Project/scripts/01_data_prep.R", echo = TRUE)
# Convert categorical variables
df <- df %>%
mutate(
transaction_channel = as.factor(transaction_channel),
card_type = as.factor(card_type),
country = as.factor(country),
merchant = as.factor(merchant),
is_fraud = as.factor(is_fraud)
)
# Convert categorical variables
df <- df%>%
mutate(
transaction_channel = as.factor(transaction_channel),
card_type = as.factor(card_type),
country = as.factor(country),
merchant = as.factor(merchant),
is_fraud = as.factor(is_fraud)
)
# Save cleaned data
write_csv(df, "data/processed/fraud_clean.csv")
# Convert categorical variables
df <- df %>%
mutate(
transaction_channel = as.factor(transaction_channel),
card_type = as.factor(card_type),
country = as.factor(country),
merchant = as.factor(merchant),
is_fraud = as.factor(is_fraud)
)
df <- read_excel("data/raw/FNB Fraud Case Study Dataset.xlsx")
# Convert categorical variables
df <- df %>%
mutate(
transaction_channel = as.factor(transaction_channel),
card_type = as.factor(card_type),
country = as.factor(country),
merchant = as.factor(merchant),
is_fraud = as.factor(is_fraud)
)
# Convert categorical variables
df <- df %>%
mutate(
transaction_channel = as.factor(transaction_channel),
card_type = as.factor(card_type),
country = as.factor(country),
merchant = as.factor(merchant),
is_fraud = as.factor(is_fraud)
)
search()
search()
# Load libraries FIRST
library(tidyverse)
install.packages(c(
"tidyverse",
"readxl",
"lubridate",
"caret",
"rpart",
"rpart.plot",
"pROC"
))
iinstall.packages(c("tidyverse", "readxl", "lubridate", "caret", "rpart", "rpart.plot", "pROC"))
library(tidyverse)
install.packages(c("tidyverse", "readxl", "lubridate", "caret", "rpart", "rpart.plot", "pROC"))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
install.packages("rmarkdown")
install.packages("knitr")
install.packages("rmarkdown")
install.packages("knitr")
# For PDF support
install.packages("tinytex")
tinytex::install_tinytex() # Run this after installing the package
install.packages("tinytex")
# For advanced table formatting
install.packages("kableExtra")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)    # For data manipulation (pandas/numpy equivalent)
library(caret)        # For ML training, splitting, and scaling (sklearn equivalent)
library(randomForest) # For the Random Forest classifier
install.packages(randomForest) # For the Random Forest classifier
install.packages("randomForest") # For the Random Forest classifier
install.packages("themis")       # For SMOTE (imblearn equivalent)
install.packages("recipes")      # For data preprocessing pipelines
install.packages("corrplot")
install.packages("recipes")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)    # For data manipulation
library(caret)        # For ML training and splitting
library(randomForest) # For the Random Forest classifier
library(themis)       # For SMOTE balancing
library(recipes)      # For data preprocessing pipelines
library(corrplot)     # For correlation visualization
library(pROC)         # For ROC curves
library(readxl)       # Added: Necessary to read .xlsx files
library(ROCR)         # Added: Necessary for the 'prediction' and 'performance' functions
install.packages("ROCR")
knitr::opts_chunk$set(echo = TRUE)
summary(climate_raw )
climate_raw <- read_delim("data/climate_data.csv", delim = ";", show_col_types = FALSE, skip = 1)
source("~/.active-rstudio-document", echo = TRUE)
install.packages("languageserver")
setwd("G:/My Drive/3rd Year/Semester 1/STSM3734 - Causal inference - ANOVA & regression/Assessments/Assignment 1 - Group 8")
# Save to CSV
write.csv(student_data, "UFS_Student_Expenditure_Data.csv", row.names = FALSE)
# Set seed for reproducibility
set.seed(2026)
# Number of observations
n <- 100
# 1. X2: Living Arrangement (Categorical: 1=Res, 2=Off-campus, 3=Private)
living_arrangement <- sample(c(1, 2, 3), n, replace = TRUE, prob = c(0.3, 0.4, 0.3))
# 2. X3: Distance from Campus (Continuous - Correlated with Living Arrangement)
distance_km <- ifelse(living_arrangement == 1, abs(rnorm(n, 0.1, 0.05)),
ifelse(living_arrangement == 2, abs(rnorm(n, 5, 2)),
abs(rnorm(n, 12, 4))))
# 3. X1: Funding Source (Binary: 1=NSFAS/Bursary, 0=Private)
prob_funding <- ifelse(living_arrangement == 3, 0.2, 0.7)
funding_source <- rbinom(n, 1, prob_funding)
# 4. X4: Social Outings (Count variable)
social_outings <- rpois(n, lambda = 4)
# 5. X5: Library Visits (Nuisance Variable)
# X5 is defined as a base amount minus 20% of Social Outings (X4)
base_library_visits <- rpois(n, lambda = 15)
library_visits <- round(pmax(base_library_visits - (0.20 * social_outings), 0))
# Interaction Term - Funding * Outings (Used in True Model, but not a standalone column)
interaction_term <- funding_source * social_outings
# 6. The "True Model" for Expenditure (Y)
# X5 (Library Visits) is intentionally EXCLUDED from this equation so its true beta is 0.
living_effect <- ifelse(living_arrangement == 1, 0,
ifelse(living_arrangement == 2, 300, 1500))
error <- rnorm(n, mean = 0, sd = 500)
monthly_expenditure_Y <- 2500 + (1200 * funding_source) + (400 * social_outings) +
(200 * interaction_term) + living_effect + error
# Create the Data Frame
student_data <- data.frame(
funding_source = funding_source,
living_arrangement = as.factor(living_arrangement),
distance_km = round(distance_km, 2),
social_outings = social_outings,
library_visits = library_visits,
monthly_expenditure_Y = round(monthly_expenditure_Y, 2)
)
# Save to CSV
write.csv(student_data, "UFS_Student_Expenditure_Data.csv", row.names = FALSE)
# Save to CSV
write.csv(student_data, "UFS_Student_Expenditure_Data2.csv", row.names = FALSE)
